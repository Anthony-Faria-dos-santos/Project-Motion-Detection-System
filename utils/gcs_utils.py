# Utilitaires Google Cloud Storage - Projet Motion Detection System
# J'ai appris √† utiliser Google Cloud en suivant la documentation officielle
# TODO: Am√©liorer la gestion d'erreurs quand j'aurai plus de temps

import os
from google.cloud import storage
from datetime import datetime
import logging
from dotenv import load_dotenv

# Je charge les variables d'environnement
load_dotenv()

# Je configure le logging pour voir ce qui se passe
# Mon prof m'a dit que c'est important pour d√©bugger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration depuis les variables d'environnement
GOOGLE_CLOUD_BUCKET = os.getenv('GOOGLE_CLOUD_BUCKET')
GOOGLE_CLOUD_PROJECT = os.getenv('GOOGLE_CLOUD_PROJECT')

def upload_image_to_gcs(image_path, bucket_name=None):
    """
    Upload une image vers Google Cloud Storage
    J'ai copi√© cette fonction depuis la documentation Google
    """
    try:
        # Je r√©cup√®re le nom du bucket depuis les variables d'environnement
        # Si c'est pas d√©fini, j'utilise une valeur par d√©faut
        if bucket_name is None:
            bucket_name = GOOGLE_CLOUD_BUCKET
            if not bucket_name:
                print("Erreur: Nom du bucket Google Cloud non d√©fini!")
                print("Ajoutez GOOGLE_CLOUD_BUCKET dans votre fichier .env")
                return False

        # Je cr√©e un client Google Cloud Storage
        storage_client = storage.Client()
        
        # Je r√©cup√®re le bucket
        bucket = storage_client.bucket(bucket_name)
        
        # Je cr√©e un nom de fichier unique avec la date
        # Format: captures/2024/01/15/motion_14-30-25.jpg
        timestamp = datetime.now()
        year = timestamp.strftime("%Y")
        month = timestamp.strftime("%m")
        day = timestamp.strftime("%d")
        time_str = timestamp.strftime("%H-%M-%S")
        
        # Je construis le chemin dans le bucket
        blob_name = f"captures/{year}/{month}/{day}/motion_{time_str}.jpg"
        
        # Je cr√©e un "blob" (c'est comme un fichier dans le cloud)
        blob = bucket.blob(blob_name)
        
        # J'upload le fichier
        print(f"Upload en cours vers Google Cloud: {blob_name}")
        blob.upload_from_filename(image_path)
        
        print(f"Upload r√©ussi! Fichier disponible dans le bucket: {blob_name}")
        return True
        
    except Exception as e:
        # Si quelque chose va mal, j'affiche l'erreur
        print(f"Erreur lors de l'upload vers Google Cloud: {e}")
        print("V√©rifiez que:")
        print("1. Votre fichier .env contient les bonnes cl√©s")
        print("2. Vous avez activ√© l'API Google Cloud Storage")
        print("3. Votre compte a les bonnes permissions")
        return False

def test_gcs_connection():
    """
    Test simple pour v√©rifier que la connexion Google Cloud fonctionne
    J'ai ajout√© cette fonction pour d√©bugger les probl√®mes de connexion
    """
    try:
        print("Test de connexion √† Google Cloud Storage...")
        
        # Je r√©cup√®re le nom du bucket
        bucket_name = GOOGLE_CLOUD_BUCKET
        if not bucket_name:
            print("‚ùå Erreur: GOOGLE_CLOUD_BUCKET non d√©fini dans .env")
            return False
        
        # Je teste la connexion
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        
        # Je v√©rifie si le bucket existe
        if bucket.exists():
            print(f"‚úÖ Connexion r√©ussie! Bucket '{bucket_name}' trouv√©")
            return True
        else:
            print(f"‚ùå Erreur: Bucket '{bucket_name}' n'existe pas")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur de connexion: {e}")
        print("V√©rifiez votre configuration Google Cloud")
        return False

def list_recent_captures(bucket_name=None, limit=10):
    """
    Liste les captures r√©centes dans le bucket
    Utile pour v√©rifier que les uploads fonctionnent
    """
    try:
        if bucket_name is None:
            bucket_name = GOOGLE_CLOUD_BUCKET
            if not bucket_name:
                print("Erreur: Nom du bucket non d√©fini")
                return []
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        
        # Je liste les fichiers dans le dossier captures
        blobs = bucket.list_blobs(prefix="captures/")
        
        # Je trie par date (les plus r√©cents en premier)
        files = []
        for blob in blobs:
            files.append({
                'name': blob.name,
                'created': blob.time_created,
                'size': blob.size
            })
        
        # Je trie par date de cr√©ation (plus r√©cent en premier)
        files.sort(key=lambda x: x['created'], reverse=True)
        
        print(f"üìÅ {len(files)} captures trouv√©es dans Google Cloud Storage")
        
        # J'affiche les plus r√©centes
        for i, file in enumerate(files[:limit]):
            print(f"{i+1}. {file['name']} ({file['created'].strftime('%Y-%m-%d %H:%M:%S')})")
        
        return files
        
    except Exception as e:
        print(f"Erreur lors de la liste des captures: {e}")
        return []

# Fonction pour nettoyer les anciens fichiers (optionnel)
def cleanup_old_captures(bucket_name=None, days_to_keep=30):
    """
    Supprime les captures plus anciennes que X jours
    J'ai ajout√© √ßa pour √©viter de remplir le bucket
    TODO: Am√©liorer cette fonction
    """
    try:
        if bucket_name is None:
            bucket_name = GOOGLE_CLOUD_BUCKET
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        
        # Je calcule la date limite
        from datetime import timedelta
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        print(f"Nettoyage des captures plus anciennes que {days_to_keep} jours...")
        
        # Je liste et supprime les anciens fichiers
        blobs = bucket.list_blobs(prefix="captures/")
        deleted_count = 0
        
        for blob in blobs:
            if blob.time_created < cutoff_date:
                blob.delete()
                deleted_count += 1
                print(f"Supprim√©: {blob.name}")
        
        print(f"Nettoyage termin√©: {deleted_count} fichiers supprim√©s")
        return deleted_count
        
    except Exception as e:
        print(f"Erreur lors du nettoyage: {e}")
        return 0
